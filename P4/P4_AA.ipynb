{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4\n",
    "# Aprendizaje de redes neuronales\n",
    "> Realizado por Andrés puente y Francisco López"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import displayData as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import checkNNGradients as check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = loadmat('ex4data1.mat')\n",
    "Y = data['y']\n",
    "X = data['X']\n",
    "\n",
    "nMuestras = len(X)\n",
    "Y = np.ravel(Y)\n",
    "\n",
    "\n",
    "print(Y[2222])\n",
    "plt.figure()\n",
    "dp.displayImage(X[2222])\n",
    "plt.savefig(\"Input_sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = loadmat('ex4weights.mat')\n",
    "theta1,theta2 = weights['Theta1'],weights['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGMOIDE \n",
    "def sigmoide(value):\n",
    "    return 1/(1+np.exp(-value))\n",
    "def sigmoideDerivada(value):\n",
    "    temp = sigmoide(value)\n",
    "    return temp * (1 - temp)\n",
    "\n",
    "def pesosAleatorios(L_in,L_out):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retro-propagacion -> Forward propagation\n",
    "El algoritmo de retro-propagación nos permite calcular el gradiente de la función de coste de la red neuronal.\n",
    "\n",
    "Para ello se utilizaran 2 funciones, forwardProp y backprop.\n",
    "\n",
    "ForwardProp es una funcion de hipotesis que utiliza un valor de entrada para predecir una salida mediante una matriz de pesos. Tambien añadira un termino de sesgo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor predecido para el elemento 0 de X segun la hipotesis:  9\n"
     ]
    }
   ],
   "source": [
    "def forwardProp(th1, th2, X):\n",
    "    z1 = th1.dot(X.T)\n",
    "    a1 = sigmoide(z1)\n",
    "    tuple = (np.ones(len(a1[0])), a1)\n",
    "    a1 = np.vstack(tuple)\n",
    "    z2 = th2.dot(a1)\n",
    "    a2 = sigmoide(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "X_aux = np.hstack([np.ones((len(X), 1), dtype = np.float), X])\n",
    "print(\"Valor predecido para el elemento 0 de X segun la hipotesis: \", \n",
    "      (forwardProp(theta1, theta2, X_aux)[3]).T[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de coste\n",
    "La función de coste, se implementara con regularización. Como entrada a dicha función, hemos de preparar un vector de Y distinto al recibido. Será una matriz de (numElementos, numEtiquetas) donde cada fila corresponde a un caso. Cada fila tendrá todos los valores a cero menos el valor real que representa ese caso, que estará a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFun(X, y, theta1, theta2, reg):\n",
    "    #Here we assert that we can operate with the parameters\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    muestras = len(y)\n",
    "\n",
    "    theta1 = np.array(theta1)\n",
    "    theta2 = np.array(theta2)\n",
    "\n",
    "    hipo  = forwardProp(theta1, theta2, X)[3]\n",
    "    cost = np.sum((-y.T)*(np.log(hipo)) - (1-y.T)*(np.log(1- hipo)))/muestras\n",
    "\n",
    "    regcost = np.sum(np.power(theta1[:, 1:], 2)) + np.sum(np.power(theta2[:,1:], 2))\n",
    "    regcost = regcost * (reg/(2*muestras))\n",
    "\n",
    "    return cost + regcost\n",
    "\n",
    "def getYMatrix(Y, nEtiquetas):\n",
    "    nY = np.zeros((len(Y), nEtiquetas))\n",
    "    yaux = np.array(Y) -1\n",
    "    #print(Y)\n",
    "    #print(len(nY))\n",
    "    \n",
    "    for i in range(len(nY)):\n",
    "        #z = yaux[i].all()\n",
    "        z = yaux[i]\n",
    "        if(isinstance(z, np.uint8)):\n",
    "            if(z == 10): z = 0\n",
    "            nY[i][z] = 1\n",
    "        else:\n",
    "            z = yaux[i].all()\n",
    "            if(z == 10): z = 0\n",
    "            nY[i][z] = 1\n",
    "                \n",
    "        #print(z)\n",
    "        #print(\"Y de ceros: \", nY)\n",
    "    return nY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El coste con thetas entrenados es:  0.3837698590909236\n"
     ]
    }
   ],
   "source": [
    "Y_aux = getYMatrix(Y, 10)\n",
    "\n",
    "print(\"El coste con thetas entrenados es: \", costFun(X_aux, Y_aux, theta1, theta2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackPropagation\n",
    "\n",
    "Backpropagation se usa para repartir el error entre las neuronas de la red neuronal. \n",
    "Comienza desde la ultima capa y desde esa desciende hasta la penúltima, ya que no se puede \n",
    "repartir error para la capa de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve el coste y el gradiente de una red neuronal de dos capas\n",
    "def backprop(params_rn, num_entradas,num_ocultas, num_etiquetas, X, Y, reg):\n",
    "    th1 = np.reshape(params_rn[:num_ocultas *(num_entradas + 1)],(num_ocultas, (num_entradas+1)))\n",
    "    # theta2 es un array de (num_etiquetas, num_ocultas)\n",
    "    th2 = np.reshape(params_rn[num_ocultas*(num_entradas + 1): ], (num_etiquetas,(num_ocultas+1)))\n",
    "    \n",
    "    X_unos = np.hstack([np.ones((len(X), 1), dtype = np.float), X])\n",
    "    nMuestras = len(X)\n",
    "    y = np.zeros((nMuestras, num_etiquetas))\n",
    "    \n",
    "    y = y + getYMatrix(Y, num_etiquetas)\n",
    "    \n",
    "    coste = costFun(X_unos, y, th1, th2, reg)\n",
    "    \n",
    "    #Backpropagation\n",
    "    \n",
    "    # Forward propagation para obtener una hipótesis y los valores intermedios\n",
    "    # de la red neuronal\n",
    "    z2, a2, z3, a3 = forwardProp(th1, th2, X_unos)\n",
    "    \n",
    "    gradW1 = np.zeros(th1.shape)\n",
    "    gradW2 = np.zeros(th2.shape)\n",
    "    \n",
    "    # Coste por capas\n",
    "    delta3 = np.array(a3 - y.T)\n",
    "    delta2 = th2.T[1:, :].dot(delta3)*sigmoideDerivada(z2)\n",
    "    \n",
    "    # Acumulacion de gradiente\n",
    "    gradW1 = gradW1 + (delta2.dot(X_unos))\n",
    "    gradW2 = gradW2 + (delta3.dot(a2.T))\n",
    "    \n",
    "    G1 = gradW1/float(nMuestras)\n",
    "    G2 = gradW2/float(nMuestras)\n",
    "    \n",
    "    # suma definitiva\n",
    "    G1[:, 1: ] = G1[:, 1:] + (float(reg)/float(nMuestras))*th1[:, 1:]\n",
    "    G2[:, 1: ] = G2[:, 1:] + (float(reg)/float(nMuestras))*th2[:, 1:]\n",
    "    \n",
    "    gradients = np.concatenate((G1, G2), axis = None)\n",
    "    \n",
    "    return coste, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencias al comprobar gradientes:\n",
      " [ 1.14376897e-10  9.90318938e-14  7.07486847e-12  3.08568171e-11\n",
      " -1.16232995e-10  2.46816456e-12 -3.54113544e-11 -1.05037631e-10\n",
      " -1.62812763e-10  9.56501545e-12 -7.94193045e-11 -2.43810860e-10\n",
      " -6.30041019e-11  7.82243714e-12 -2.59059163e-11 -7.11327802e-11\n",
      "  4.48127369e-11  9.81270620e-13  3.02057060e-11  5.07995868e-11\n",
      "  6.21963592e-11  1.66536784e-11  8.51685389e-12  4.28101998e-12\n",
      "  1.72283854e-11  1.71411774e-11  7.11513071e-11  1.42481027e-11\n",
      "  7.72014397e-12  9.40297840e-12  1.58183466e-11  2.05401252e-11\n",
      "  6.97608638e-11  1.60036429e-11  1.89406824e-12  1.83976445e-11\n",
      "  2.21590801e-11  2.11061169e-11]\n"
     ]
    }
   ],
   "source": [
    "params = np.concatenate((theta1, theta2), axis = None)\n",
    "print(\"Diferencias al comprobar gradientes:\\n\", check.checkNNGradients(backprop, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializacion aleatoria de thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitRandomWeight(L_in, L_out):\n",
    "    cini = 0.2\n",
    "    a = np.random.uniform(-cini, cini, size = (L_in, L_out))\n",
    "    a = np.insert(a, 0, 1, axis = 0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de la red Neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNTest (num_entradas, num_ocultas, num_etiquetas, reg, X, Y, laps):\n",
    "    t1 = InitRandomWeight(num_entradas, num_ocultas)\n",
    "    t2 = InitRandomWeight(num_ocultas, num_etiquetas)\n",
    "\n",
    "    params = np.hstack((np.ravel(t1), np.ravel(t2)))\n",
    "    out = opt.minimize(fun = backprop, x0 = params, args = (num_entradas, num_ocultas, num_etiquetas, X, Y, reg), method='TNC', jac = True, options = {'maxiter': laps})\n",
    "\n",
    "    Thetas1 = out.x[:(num_ocultas*(num_entradas+1))].reshape(num_ocultas,(num_entradas+1))\n",
    "    Thetas2 = out.x[(num_ocultas*(num_entradas+1)):].reshape(num_etiquetas,(num_ocultas+1))\n",
    "\n",
    "    input = np.hstack([np.ones((len(X), 1), dtype = np.float), X])\n",
    "    hipo = forwardProp(Thetas1, Thetas2, input)[3]\n",
    "\n",
    "\n",
    "    Ghipo = (hipo.argmax(axis = 0))+1\n",
    "    prec = (Ghipo == Y)*1\n",
    "    \n",
    "    precision = sum(prec) / len(X)\n",
    "\n",
    "    print(\"Program precision: \", precision *100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  91.10000000000001 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  99.14 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  18.099999999999998 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
